weights = rep(1/n,n)
stop_flag = FALSE
G = list()
alp = NULL
m = 1
while(!stop_flag)
{
rp = rpart(formula,data=data,weights=weights,control=
rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0))
pre = predict(rp,data,type='class')
pre = as.numeric(as.character(pre))*2-1
ind = which(pre!=y)
err = sum(weights[ind])
if (err==0)
stop_flag=TRUE
else
{
alpha = log((1-err)/err)/2
weights = weights*exp(-alpha*y*pre)
weights = weights/sum(weights)
G[[m]] = rp
alp[m] = alpha
m = m+1
}
if (m>iter_num)
stop_flag = TRUE
}
return(list(G,alp))
}
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
?model.response
Adaboost = function(formula,data,func,iter_num, ...)
{
cl <- match.call()
mf <- match.call(expand.dots = FALSE)
m <- match(c("formula", "data", "subset", "weights", "na.action",
"offset"), names(mf), 0L)
mf <- mf[c(1L, m)]
mf$drop.unused.levels <- TRUE
mf[[1L]] <- quote(stats::model.frame)
mf <- eval(mf, parent.frame())
mt <- attr(mf, "terms")
y <- model.response(mf, "any")
y = as.numeric(as.character(y))*2-1
n = length(y)
weights = rep(1/n,n)
stop_flag = FALSE
G = list()
alp = NULL
m = 1
while(!stop_flag)
{
rp = rpart(formula,data=data,weights=weights,control=
rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0))
pre = predict(rp,data,type='class')
pre = as.numeric(as.character(pre))*2-1
ind = which(pre!=y)
err = sum(weights[ind])
if (err==0)
stop_flag=TRUE
else
{
alpha = log((1-err)/err)/2
weights = weights*exp(-alpha*y*pre)
weights = weights/sum(weights)
G[[m]] = rp
alp[m] = alpha
m = m+1
}
if (m>iter_num)
stop_flag = TRUE
}
return(list(G,alp))
}
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
debug(Adaboost)
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
y
weights
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
formula
data
weights
class(weights)
debug(rpart)
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
indx
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
temp
weights
Adaboost = function(formula,data,func,iter_num, ...)
{
cl <- match.call()
mf <- match.call(expand.dots = FALSE)
m <- match(c("formula", "data", "subset", "weights", "na.action",
"offset"), names(mf), 0L)
mf <- mf[c(1L, m)]
mf$drop.unused.levels <- TRUE
mf[[1L]] <- quote(stats::model.frame)
mf <- eval(mf, parent.frame())
mt <- attr(mf, "terms")
y <- model.response(mf, "any")
y = as.numeric(as.character(y))*2-1
n = length(y)
weights = rep(1/n,n)
stop_flag = FALSE
G = list()
alp = NULL
m = 1
environment(formula)<-environment()
while(!stop_flag)
{
rp = rpart(formula,data=data,weights=weights,control=
rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0))
pre = predict(rp,data,type='class')
pre = as.numeric(as.character(pre))*2-1
ind = which(pre!=y)
err = sum(weights[ind])
if (err==0)
stop_flag=TRUE
else
{
alpha = log((1-err)/err)/2
weights = weights*exp(-alpha*y*pre)
weights = weights/sum(weights)
G[[m]] = rp
alp[m] = alpha
m = m+1
}
if (m>iter_num)
stop_flag = TRUE
}
return(list(G,alp))
}
undebug(rpart)
debug(Adaboost)
Adaboost(y~x,data=dat,func=rpart,iter_num=10)
weights
pre
ind
weights
err
ind
weights
ind
err
weights
Adaboost = function(formula,data,func,iter_num,eps=1e-8 ...)
{
cl <- match.call()
mf <- match.call(expand.dots = FALSE)
m <- match(c("formula", "data", "subset", "weights", "na.action",
"offset"), names(mf), 0L)
mf <- mf[c(1L, m)]
mf$drop.unused.levels <- TRUE
mf[[1L]] <- quote(stats::model.frame)
mf <- eval(mf, parent.frame())
mt <- attr(mf, "terms")
y <- model.response(mf, "any")
y = as.numeric(as.character(y))*2-1
n = length(y)
weights = rep(1/n,n)
pre_weights = weights
stop_flag = FALSE
G = list()
alp = NULL
m = 1
environment(formula)<-environment()
while(!stop_flag)
{
rp = rpart(formula,data=data,weights=weights,control=
rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0))
pre = predict(rp,data,type='class')
pre = as.numeric(as.character(pre))*2-1
ind = which(pre!=y)
err = sum(weights[ind])
if (err==0)
stop_flag=TRUE
else
{
alpha = log((1-err)/err)/2
weights = weights*exp(-alpha*y*pre)
weights = weights/sum(weights)
G[[m]] = rp
alp[m] = alpha
m = m+1
}
if (m>iter_num)
stop_flag = TRUE
if (sum((pre_weights-weights)^2)<eps)
stop_flag=TRUE
}
return(list(G,alp))
}
Adaboost = function(formula,data,func,iter_num,eps=1e-8, ...)
{
cl <- match.call()
mf <- match.call(expand.dots = FALSE)
m <- match(c("formula", "data", "subset", "weights", "na.action",
"offset"), names(mf), 0L)
mf <- mf[c(1L, m)]
mf$drop.unused.levels <- TRUE
mf[[1L]] <- quote(stats::model.frame)
mf <- eval(mf, parent.frame())
mt <- attr(mf, "terms")
y <- model.response(mf, "any")
y = as.numeric(as.character(y))*2-1
n = length(y)
weights = rep(1/n,n)
pre_weights = weights
stop_flag = FALSE
G = list()
alp = NULL
m = 1
environment(formula)<-environment()
while(!stop_flag)
{
rp = rpart(formula,data=data,weights=weights,control=
rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0))
pre = predict(rp,data,type='class')
pre = as.numeric(as.character(pre))*2-1
ind = which(pre!=y)
err = sum(weights[ind])
if (err==0)
stop_flag=TRUE
else
{
alpha = log((1-err)/err)/2
weights = weights*exp(-alpha*y*pre)
weights = weights/sum(weights)
G[[m]] = rp
alp[m] = alpha
m = m+1
}
if (m>iter_num)
stop_flag = TRUE
if (sum((pre_weights-weights)^2)<eps)
stop_flag=TRUE
}
return(list(G,alp))
}
Adaboost(y~x,data=dat,func=rpart,iter_num=10,eps=1e-8)
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
tmp = Adaboost(y~x,data=dat,func=rpart,iter_num=10,eps=1e-8)
str(tmp)
tmp$Err
names(tmp)
tmp[[3]]
tmp[[2]]
x=rnorm(10)
y=x^2+rnorm(10,0,0.1)
y
summary(y)
dat$x = x
dat$y = as.factor(as.numeric(y>0.5))
dat
tmp = Adaboost(y~x,data=dat,func=rpart,iter_num=50,eps=1e-8)
tmp[[3]]
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
getData()
hire = getData()
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
hire = getData()
hire
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
tmp = Adaboost(class~.,data=hire,iter_num=10,eps=1e-8)
require(rprat)
require(rpart)
tmp = Adaboost(class~.,data=hire,iter_num=10,eps=1e-8)
tmp[[2]]
tmp[[3]]
debug(Adaboost)
tmp = Adaboost(class~.,data=hire,iter_num=10,eps=1e-8)
ind
weight
weights
pre_weights
weights
ind
err
weights
sum(weights)
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
undebug(Adaboost)
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
debug(AdaboostTree)
source('~/文档/Boost_Tree/Adaboost_Rpart.R')
AdaboostTree = function(formula,data,iter_num,eps=1e-8, ...)
{
cl <- match.call()
mf <- match.call(expand.dots = FALSE)
m <- match(c("formula", "data", "subset", "weights", "na.action",
"offset"), names(mf), 0L)
mf <- mf[c(1L, m)]
mf$drop.unused.levels <- TRUE
mf[[1L]] <- quote(stats::model.frame)
mf <- eval(mf, parent.frame())
mt <- attr(mf, "terms")
y <- model.response(mf, "any")
y = as.numeric(as.character(y))*2-1
n = length(y)
weights = rep(1/n,n)
pre_weights = weights
stop_flag = FALSE
G = list()
alp = NULL
Err = NULL
m = 1
environment(formula)<-environment()
while(!stop_flag)
{
rp = rpart(formula,data=data,weights=weights,control=
rpart.control(maxdepth=1,cp=-1,minsplit=0,xval=0))
pre = predict(rp,data,type='class')
pre = as.numeric(as.character(pre))*2-1
ind = which(pre!=y)
err = sum(weights[ind])
if (length(ind)==0)
stop_flag=TRUE
else
{
alpha = log((1-err)/err)/2
pre_weights = weights
weights = weights*exp(-alpha*y*pre)
weights = weights/sum(weights)
G[[m]] = rp
alp[m] = alpha
Err[m] = err
m = m+1
}
if (m>iter_num)
stop_flag = TRUE
if (sum((pre_weights-weights)^2)<eps)
stop_flag=TRUE
}
return(list(G,alp,Err))
}
getData = function()
{
body = c(0,0,1,1,1,0,1,1,1,0)
work = c(1,3,2,1,2,1,1,1,3,2)
potential = c(3,1,2,3,3,2,2,1,1,1)
class = as.factor(c(-1,-1,-1,-1,-1,-1,1,1,-1,-1))
ans = data.frame(body,work,potential,class)
return(ans)
}
hire = getData()
strong_classifier = AdaboostTree(class~.,data=hire,iter_num=10,eps=1e-8)
debug(AdaboostTree)
strong_classifier = AdaboostTree(class~.,data=hire,iter_num=10,eps=1e-8)
weights
pre_weights
weights
eps
pre_weights - weights
sum((pre_weights - weights)^2)
sum((pre_weights - weights)^2)
sum((pre_weights - weights)^2)
m
sum((pre_weights - weights)^2)
alp
Err
sum((pre_weights - weights)^2)
ind
weight
weights
pre_weights
strong_classifier = AdaboostTree(class~.,data=hire,iter_num=10,eps=1e-8)
m
m
m
m
m
sum((pre_weights - weights)^2)
m
sum((pre_weights - weights)^2)
m
sum((pre_weights - weights)^2)
pre
m
sum((pre_weights - weights)^2)
pre_weights
weights
pre
sum(pre_weights)
install.packages("tmcn",repos="http://r-forge.r-project.org")
200^2-4*199
sqrt(200^2-4*199)
(200+198)/2
(200-198)/2
1e18
a=1e18
a^2
class(a^2)
typeof(a^2)
1e18-1e17
a=1e18-1e17
a^2
sqrt(a^2)
library("tmcn", lib.loc="/home/hetong/R/i686-pc-linux-gnu-library/3.0")
install.packages("tmcn.crfpp",repos="http://r-forge.r-project.org")
install.packages("tmcn.word2vec",repos="http://r-forge.r-project.org")
install.packages("tmcn.word2vec",repos="http://r-forge.r-project.org")
library("tmcn.crfpp", lib.loc="/home/hetong/R/i686-pc-linux-gnu-library/3.0")
require(tmcn.crfpp)
library("tmcn", lib.loc="/home/hetong/R/i686-pc-linux-gnu-library/3.0")
require(tmcn.crfpp)
TestFilePath<-system.file("tests",package="tmcn.crfpp")
WorkPath <- tempdir()
TempletFile <- file.path(TestFilePath,
"testdata", "chunking_template")
TrainingFile <- file.path(TestFilePath,
"testdata", "chunking_train")
ModelFile1 <- file.path(WorkPath, "output", "model1")
TempletFile
res1 <- crflearn(TempletFile, TrainingFile, ModelFile1)
tmp='吃葡萄不吐葡萄皮不吃葡萄倒吐葡萄皮'
strsplit(tmp,'')[[1]]
tmp=strsplit(tmp,'')[[1]]
tmp
tmp = cbind(tmp,c(tmp[-1],NA))
tmp
tmp = cbind(tmp,c(tmp[-1,2],NA))
tmp
tmp = cbind(tmp,c(tmp[-1,3],NA))
tmp
tmp = cbind(tmp,c(tmp[-1,4],NA))
tmp
?paste
paste(tmp)
paste(tmp,sep='')
paste(tmp,sep='',collapse='')
paste(tmp,sep=',',collapse='')
paste(tmp[,1],tmp[,2])
paste(tmp[,1],tmp[,2],collapse='')
paste(tmp[,1],tmp[,2],sep='')
library(Matrix);
n <- 8192;
X <- Hilbert(n);
A <- nearPD(X);
system.time(B <- chol(A$mat));
library(Matrix);
n <- 1024;
X <- Hilbert(n);
A <- nearPD(X);
system.time(B <- chol(A$mat));
library(Matrix);
n <- 2048;
X <- Hilbert(n);
A <- nearPD(X);
system.time(B <- chol(A$mat));
source('~/github/WordSplit/title_parallel_functions.R')
source('~/github/WordSplit/title_parallel_Running.R')
writeLines(rep('1 ',5000),file='test.txt')
writeLines(rep('1 ',5000),'test.txt')
writeChar(rep('1 ',5000),'test.txt')
writeLines(rep('1 ',5000),'test.txt')
paste(1:5)
writeLines(paste(1:5000,sep=' '),'test.txt')
writeLines(paste(1:50,sep=' '),'test.txt')
writeLines(paste(1:500,sep=' '),'test.txt')
require(devtools)
isUTF8
require(tmcn)
setwd('~/github/SegCN/')
load_all()
load_all()
txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
txt = unlist(strsplit(txt,''))
txt=readLines('~/github/WordSplit/wuxia/越女剑.txt')
txt=toUTF8(txt)
txt = unlist(strsplit(txt,''))
txt=txt[txt!='']
ws = BaumWelch(txt)
load_all()
ws = BaumWelch(txt)
ws[[1]]
ws[[3]]
txt[1:5]
ws[[2]][,1:5]
unique(txt)[1:5]
txt[1:50]
?rowMax
load_all()
debug(BaumWelch)
ws = BaumWelch(txt)
load_all()
debug(BaumWelch)
ws = BaumWelch(txt,maxiter=5)
txt[1:100]
dict[txt[1:100]]
path[1:100]
c('B','M','E','S')[path[1:100]]
cbind(dict[txt[1:100]],c('B','M','E','S')[path[1:100]])
cbind(dict[txt[1001:1100]],c('B','M','E','S')[path[1001:1100]])
ws[[1]]
txt= readLines('~/github/WordSplit/wuxia/雪山飞狐.txt')
txt=toUTF8(txt)
txt=strsplit(txt,'')
txt=unlist(txt)
txt=txt[txt!='']
txt[1:20]
length(txt)
ws = BaumWelch(txt,maxiter=1000,leps=0.1)
undebug(BaumWelch)
ws = BaumWelch(txt,maxiter=1000,leps=0.1)
ws = BaumWelch(txt,maxiter=300,leps=0.1)
ws = BaumWelch(txt,maxiter=300,leps=50)
ws[[4]][1:5]
save(ws,file='ws.rda')
